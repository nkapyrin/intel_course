Software
• Библиотека машинного зрения OpenCV (C, C++, интерфейс для Python) (раздел
ML) http://opencv.org/
• Система для статистических вычислений R http://www.r-project.org/
• Библиотека Scikit-learn (Python) http://scikit-learn.org/
• Библиотека алгоритмов для анализа данных Weka (Java)
http://www.cs.waikato.ac.nz/~ml/weka/
• Пакет для решения задач машинного обучения и анализа данных Orange
http://orange.biolab.si/
• ...
• Данные для экспериментов: UCI Machine Learning Repository
http://archive.ics.uci.edu/ml/




p135

Метод главных компонент
Метод главных компонент (Principal Compoinent Analysis, PCA) — один из основных,
«классических», методов понижения размерности.
Sylvester J.J. On the reduction of a bilinear quantic of the nth order to the form of a sum of
n products by a double orthogonal substitution. Messenger of Mathematics, 19, 42–46 (1889)
Pearson C. On lines and planes of closest fit to systems of points in space. Phil. Mag.,
Series B., 2 (11), 559–572 (1901)
Джеймс Джозеф Сильвестр (1814–1897) — английский математик. Несколько лет
работал в США. Основал «American Journal of Mathematics».
Карл Пирсон (1857–1936) — английский математик, статистик и биолог. Основатель
математической статистики.

x (1) , x (2) , . . . , x (N ) ∈ R d .

Рассмотрим следующие задачи:
1) Аппроксимировать данные линейными многообразиями меньшей размерности:
найти линейное многообразие заданной (< d) размерности, сумма квадратов
расстояний до которого минимальна.
2) Найти подпространство заданной размерности, в ортогональной проекции на
которое разброс (выборочная дисперсия) данных максимален.
3) Найти подпространство заданной размерности, в ортогональной проекции на
которое среднеквадратичное расстояние между каждой парой точек максимально.
Все эти задачи имеют одно и то же решение — PCA.
Многочисленные обобщения (в том числе нелинейные): хорошо приспособленный
базис (Ю. И. Неймарк), метод главных кривых и многообразий, поиск наилучшей
проекции (Projection Pursuit), самоорганизующиеся карты Кохонена и т. д.





